{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, explode,substring, length, udf\n",
    "from pyspark.sql.types import DecimalType, StringType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from itertools import cycle\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fbf5f5ba910>\n",
      "3.0.0-preview2\n"
     ]
    }
   ],
   "source": [
    "# Setting up spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "print(spark)\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topinves_df=spark.read.csv(\"hdfs://localhost:9000/eda/dc_investments.csv\", header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['_c0', 'company_permalink','investor_permalink','funding_round_permalink']\n",
    "topinves_df = topinves_df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- company_category_list: string (nullable = true)\n",
      " |-- company_country_code: string (nullable = true)\n",
      " |-- company_region: string (nullable = true)\n",
      " |-- company_city: string (nullable = true)\n",
      " |-- investor_name: string (nullable = true)\n",
      " |-- investor_country_code: string (nullable = true)\n",
      " |-- funding_round_type: string (nullable = true)\n",
      " |-- funded_at: string (nullable = true)\n",
      " |-- raised_amount_usd: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topinves_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+----------------------------+\n",
      "|raised_amount_usd|funded_at |company_category_list       |\n",
      "+-----------------+----------+----------------------------+\n",
      "|500000.0         |2009-05-15|Art|E-Commerce|Marketplaces |\n",
      "|500000.0         |2009-05-15|Art|E-Commerce|Marketplaces |\n",
      "|500000.0         |2009-05-15|Art|E-Commerce|Marketplaces |\n",
      "|6602693.89911084 |2015-11-04|Local Businesses|Restaurants|\n",
      "|1736910.0        |2013-11-13|Local Businesses|Restaurants|\n",
      "+-----------------+----------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topinves_df.select('raised_amount_usd', 'funded_at','company_category_list').filter(topinves_df.company_category_list.contains('|')).show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+-------------+\n",
      "|raised_amount_usd|year|category_list|\n",
      "+-----------------+----+-------------+\n",
      "|        2000000.0|2008|[Curated Web]|\n",
      "|        6000000.0|2014|   [Software]|\n",
      "|          41250.0|2014|      [Games]|\n",
      "|            2.0E7|2015|  [Analytics]|\n",
      "|        3000000.0|2013|  [Analytics]|\n",
      "+-----------------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitCategory = topinves_df.select('raised_amount_usd',  substring('funded_at',-0,4).cast('int').alias('year')\n",
    "                       , split(col(\"company_category_list\")\n",
    "                       , \"[|]s*\").alias(\"category_list\")).filter(col('year') >= 1990)\n",
    "splitCategory.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+-----------+\n",
      "|raised_amount_usd|year|   category|\n",
      "+-----------------+----+-----------+\n",
      "|        2000000.0|2008|Curated Web|\n",
      "|        6000000.0|2014|   Software|\n",
      "|          41250.0|2014|      Games|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        3000000.0|2013|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        1700000.0|2013|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "|            2.0E7|2015|  Analytics|\n",
      "|        8900000.0|2014|  Analytics|\n",
      "+-----------------+----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "open_list=splitCategory.select('raised_amount_usd','year', explode('category_list').alias('category'))\n",
    "open_list.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_list.createOrReplaceTempView(\"comparision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2 =  \"\"\"\n",
    "            SELECT CATEGORY, \n",
    "            CAST(YEAR AS INT), \n",
    "            SUM(RAISED_AMOUNT_USD) AS TOTAL, \n",
    "            CAST(SUM(RAISED_AMOUNT_USD) AS DECIMAL(30)) AS TOTAL_DEC \n",
    "            FROM comparision GROUP \n",
    "            BY CATEGORY, YEAR \n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+----------+\n",
      "|            CATEGORY|YEAR|              TOTAL| TOTAL_DEC|\n",
      "+--------------------+----+-------------------+----------+\n",
      "|      Interest Graph|2011|             1.86E7|  18600000|\n",
      "|  Big Data Analytics|2013|      2.474244075E9|2474244075|\n",
      "|           Aerospace|2014|4.575373451009297E8| 457537345|\n",
      "|               Audio|2005|            1.118E8| 111800000|\n",
      "|Cloud Infrastructure|2010|       1.26510796E8| 126510796|\n",
      "|    Cloud Management|2010|           5.5378E8| 553780000|\n",
      "|                Apps|2008|6.918205280557648E8| 691820528|\n",
      "+--------------------+----+-------------------+----------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.sql(sql2)\n",
    "df2.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------------+\n",
      "|            CATEGORY|FEATURES|              TOTAL|\n",
      "+--------------------+--------+-------------------+\n",
      "|      Interest Graph|[2011.0]|             1.86E7|\n",
      "|  Big Data Analytics|[2013.0]|      2.474244075E9|\n",
      "|           Aerospace|[2014.0]|4.575373451009297E8|\n",
      "|               Audio|[2005.0]|            1.118E8|\n",
      "|Cloud Infrastructure|[2010.0]|       1.26510796E8|\n",
      "|    Cloud Management|[2010.0]|           5.5378E8|\n",
      "|                Apps|[2008.0]|6.918205280557648E8|\n",
      "+--------------------+--------+-------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['YEAR'], outputCol = 'FEATURES')\n",
    "featureDF = vectorAssembler.transform(df2).select('CATEGORY', 'FEATURES', 'TOTAL')\n",
    "\n",
    "featureDF.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CATEGORY: string (nullable = true)\n",
      " |-- FEATURES: vector (nullable = true)\n",
      " |-- TOTAL: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|features|              TOTAL|\n",
      "+--------+-------------------+\n",
      "|[2011.0]|             1.86E7|\n",
      "|[2013.0]|      2.474244075E9|\n",
      "|[2014.0]|4.575373451009297E8|\n",
      "+--------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['YEAR'], outputCol = 'features')\n",
    "data = vectorAssembler.transform(df2)\n",
    "data = data.select('features','TOTAL')\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train_df=splits[0]\n",
    "test_df=splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data  = 0.0282254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_be5d598359f6, depth=5, numNodes=25, numFeatures=1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "tr = DecisionTreeRegressor(featuresCol ='features', labelCol = 'TOTAL')\n",
    "\n",
    "tr_model = tr.fit(train_df)\n",
    "tr_predictions = tr_model.transform(test_df)\n",
    "tr_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"TOTAL\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rmse = tr_evaluator.evaluate(tr_predictions)\n",
    "print(\"R Squared (R2) on test data  = %g\" % rmse)\n",
    "tr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2.12511e+09\n"
     ]
    }
   ],
   "source": [
    "tr = DecisionTreeRegressor(featuresCol ='features', labelCol = 'TOTAL')\n",
    "tr_model = tr.fit(train_df)\n",
    "tr_predictions = tr_model.transform(test_df)\n",
    "tr_evaluator = RegressionEvaluator(\n",
    "labelCol=\"TOTAL\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = tr_evaluator.evaluate(tr_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|features|              TOTAL|\n",
      "+--------+-------------------+\n",
      "|[2011.0]|             1.86E7|\n",
      "|[2013.0]|      2.474244075E9|\n",
      "|[2014.0]|4.575373451009297E8|\n",
      "+--------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['YEAR'], outputCol = 'features')\n",
    "data = vectorAssembler.transform(df2)\n",
    "data = data.select('features','TOTAL')\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|Features|              label|\n",
      "+--------+-------------------+\n",
      "|[2011.0]|             1.86E7|\n",
      "|[2013.0]|      2.474244075E9|\n",
      "|[2014.0]|4.575373451009297E8|\n",
      "|[2005.0]|            1.118E8|\n",
      "|[2010.0]|       1.26510796E8|\n",
      "+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data.selectExpr(\"features as Features\", \"TOTAL as label\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------+\n",
      "|          prediction|              label|features|\n",
      "+--------------------+-------------------+--------+\n",
      "|2.6237818364195803E8|          1800000.0|[2001.0]|\n",
      "|2.6237818364195803E8|            2.844E7|[2003.0]|\n",
      "|3.2892324007344264E8|            2.986E7|[2005.0]|\n",
      "|3.2892324007344264E8|            1.118E8|[2005.0]|\n",
      "|  4.76924685647094E8|6.918205280557648E8|[2008.0]|\n",
      "+--------------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 2.53798e+09\n",
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_591848c9e12a, depth=5, numNodes=25, numFeatures=1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"Features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df)\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "treeModel = model.stages[1]\n",
    "print(treeModel) # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
